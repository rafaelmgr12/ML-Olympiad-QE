{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to drop\n",
    "\n",
    "notas = np.array(['NU_NOTA_CN','NU_NOTA_CH',\n",
    "                  'NU_NOTA_LC','NU_NOTA_MT',\n",
    "                  'NU_NOTA_REDACAO'])\n",
    "\n",
    "drop_dados = [\n",
    "    'NU_INSCRICAO', 'NO_MUNICIPIO_RESIDENCIA', 'SG_UF_RESIDENCIA',\n",
    "    'CO_MUNICIPIO_NASCIMENTO','NO_MUNICIPIO_NASCIMENTO','CO_UF_NASCIMENTO',\n",
    "    'SG_UF_NASCIMENTO']\n",
    "\n",
    "drop_escola = [\n",
    "    'CO_MUNICIPIO_ESC', 'NO_MUNICIPIO_ESC', 'CO_UF_ESC', 'SG_UF_ESC']\n",
    "\n",
    "drop_prova = [\n",
    "    'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'SG_UF_PROVA']\n",
    "\n",
    "drop_deficiencia = [\n",
    "    'IN_BAIXA_VISAO','IN_CEGUEIRA','IN_SURDEZ','IN_DEFICIENCIA_AUDITIVA',\n",
    "    'IN_SURDO_CEGUEIRA','IN_DEFICIENCIA_FISICA','IN_DEFICIENCIA_MENTAL',\n",
    "    'IN_DEFICIT_ATENCAO','IN_DISLEXIA','IN_DISCALCULIA','IN_AUTISMO',\n",
    "    'IN_VISAO_MONOCULAR','IN_OUTRA_DEF']\n",
    "\n",
    "drop_especifico = [\n",
    "    'IN_GESTANTE','IN_LACTANTE','IN_IDOSO','IN_ESTUDA_CLASSE_HOSPITALAR']\n",
    "\n",
    "drop_especializado = [\n",
    "    'IN_SEM_RECURSO','IN_ACESSO','IN_BRAILLE','IN_AMPLIADA_24','IN_AMPLIADA_18','IN_LEDOR',\n",
    "    'IN_ACESSO','IN_TRANSCRICAO','IN_LIBRAS','IN_TEMPO_ADICIONAL',\n",
    "    'IN_LEITURA_LABIAL','IN_MESA_CADEIRA_RODAS','IN_MESA_CADEIRA_SEPARADA',\n",
    "    'IN_APOIO_PERNA','IN_GUIA_INTERPRETE','IN_COMPUTADOR','IN_CADEIRA_ESPECIAL',\n",
    "    'IN_CADEIRA_CANHOTO','IN_CADEIRA_ACOLCHOADA','IN_PROVA_DEITADO','IN_MOBILIARIO_OBESO',\n",
    "    'IN_LAMINA_OVERLAY','IN_PROTETOR_AURICULAR','IN_MEDIDOR_GLICOSE','IN_MAQUINA_BRAILE',\n",
    "    'IN_SOROBAN','IN_MARCA_PASSO','IN_SONDA','IN_MEDICAMENTOS','IN_SALA_INDIVIDUAL',\n",
    "    'IN_SALA_ESPECIAL','IN_SALA_ACOMPANHANTE','IN_MOBILIARIO_ESPECIFICO',\n",
    "    'IN_MATERIAL_ESPECIFICO','IN_NOME_SOCIAL']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- feat eng\n",
    "\n",
    "## -- features socioeconomicos\n",
    "def eng_dsoec( chunk ):\n",
    "\n",
    "    chunk['Q001'] = chunk['Q001'].apply(lambda x: 1 if (x=='F') or (x=='G') \n",
    "                                              else 0).astype('int8')\n",
    "\n",
    "    chunk['Q002'] = chunk['Q002'].apply(lambda x: 1 if (x=='F') or (x=='G') \n",
    "                                              else 0).astype('int8')\n",
    "\n",
    "    chunk['Q01_2'] = chunk['Q001'] + chunk['Q002']\n",
    "    chunk.drop(['Q001','Q002'], axis=1, inplace=True)\n",
    "\n",
    "    chunk['Q003'] = chunk['Q003'].apply(lambda x: 1 if (x=='D') or (x=='E') \n",
    "                                              else 0).astype('int8')\n",
    "\n",
    "    chunk['Q004'] = chunk['Q004'].apply(lambda x: 1 if (x=='D') or (x=='E') \n",
    "                                              else 0).astype('int8')\n",
    "\n",
    "    chunk['Q03_4'] = chunk['Q003'] + chunk['Q004']\n",
    "    chunk.drop(['Q003','Q004'], axis=1, inplace=True)\n",
    "\n",
    "    chunk['Q005'] = chunk['Q005'].apply(lambda x: 1 if (x<=4) else\n",
    "                                            2 if (x>4) and (x<=8) else \n",
    "                                            3 if (x>8) and (x<20) else 4).astype('int8')\n",
    "\n",
    "    chunk['Q006'] = chunk['Q006'].apply(lambda x: 0 if (x<='C') else\n",
    "                                            1 if (x>'C') and (x<='F') else\n",
    "                                            2 if (x>'F') and (x<='I') else 3).astype('int8')\n",
    "    \n",
    "    chunk['Q007'] = chunk['Q007'].apply(lambda x: 0 if x=='A' else 1)\n",
    "    \n",
    "    chunk['Q008'] = chunk['Q008'].apply(lambda x: ord(x)- 65).astype('int8')\n",
    "    chunk['Q009'] = chunk['Q009'].apply(lambda x: ord(x)- 65).astype('int8')\n",
    "    chunk['Q08_9'] = (chunk['Q008'] + chunk['Q009']).astype('int8')\n",
    "    chunk.drop(['Q008','Q009'], axis=1, inplace=True)\n",
    "    chunk['Q08_9'] = chunk['Q08_9'].apply(lambda x: 0 if x<=3 else\n",
    "                                                    1 if (x>3) and (x<=4) else\n",
    "                                                    2 if (x>4) and (x<=6) else\n",
    "                                                    3).astype('int8')\n",
    "    \n",
    "    ## --- total de veiculos por pessoa\n",
    "    chunk['Q010'] = chunk['Q010'].apply(lambda x: ord(x)- 65).astype('int8')\n",
    "    chunk['Q011'] = chunk['Q011'].apply(lambda x: ord(x)- 65).astype('int8')\n",
    "    chunk['Q010_11'] = (chunk['Q010'] + chunk['Q011']).astype('int8')\n",
    "    chunk.drop(['Q010','Q011'], axis=1, inplace=True)\n",
    "    chunk['Q010_11'] = (chunk['Q010_11']/chunk['Q005']).astype('float16')\n",
    "    \n",
    "    ## -- total geladeira\n",
    "    chunk['Q012'] = chunk['Q012'].apply(lambda x: ord(x)- 65).astype('int8')\n",
    "    chunk['Q013'] = chunk['Q013'].apply(lambda x: ord(x)- 65).astype('int8')\n",
    "    chunk['Q012_13'] = (chunk['Q012'] + chunk['Q013']).astype('int8')\n",
    "    chunk['Q012_13'] = chunk['Q012_13'].apply(lambda x: 4 if x>= 4 else x)\n",
    "    chunk.drop(['Q012','Q013'], axis=1, inplace=True)\n",
    "    \n",
    "    ## -- total lava/seca\n",
    "    chunk['Q014'] = chunk['Q014'].apply(lambda x: ord(x)- 65).astype('int8')\n",
    "    chunk['Q015'] = chunk['Q015'].apply(lambda x: ord(x)- 65).astype('int8')\n",
    "    chunk['Q014_15'] = (chunk['Q014'] + chunk['Q015']).astype('int8')\n",
    "    chunk.drop(['Q014','Q015'], axis=1, inplace=True)\n",
    "    \n",
    "    chunk['Q016'] = chunk['Q016'].apply(lambda x: ord(x)- 65).astype('int8')\n",
    "    chunk['Q017'] = chunk['Q017'].apply(lambda x: ord(x)- 65).astype('int8')\n",
    "    chunk['Q016_17'] = (chunk['Q016'] + chunk['Q017']).astype('int8')\n",
    "    chunk.drop(['Q016','Q017'], axis=1, inplace=True)\n",
    "    \n",
    "    ## -- total sim/não\n",
    "    chunk['S/N'] = ( chunk['Q018'].apply(lambda x: ord(x) - 65) +\n",
    "                     chunk['Q020'].apply(lambda x: ord(x) - 65) +\n",
    "                     chunk['Q021'].apply(lambda x: ord(x) - 65) +\n",
    "                     chunk['Q023'].apply(lambda x: ord(x) - 65) +\n",
    "                     chunk['Q025'].apply(lambda x: ord(x) - 65)).astype('int8')\n",
    "    \n",
    "    chunk.drop(['Q018','Q020','Q021','Q023','Q025'], axis=1, inplace=True)\n",
    "    \n",
    "    chunk['Q019'] = chunk['Q019'].apply(lambda x: 0 if x<='B' else\n",
    "                                                  1 if x=='C' else\n",
    "                                                  2)\n",
    "    \n",
    "    ## -- eletrônicos / pessoa\n",
    "    chunk['Q022'] = chunk['Q022'].apply(lambda x: ord(x)- 65).astype('int8')\n",
    "    chunk['Q024'] = chunk['Q024'].apply(lambda x: ord(x)- 65).astype('int8')\n",
    "    chunk['Q022_24'] = (chunk['Q022'] + chunk['Q024']).astype('int8')\n",
    "    chunk.drop(['Q022','Q024'], axis=1, inplace=True)\n",
    "    chunk['Q022_24'] = (chunk['Q022_24']/chunk['Q005']).astype('float16')\n",
    "    \n",
    "    return chunk\n",
    "\n",
    "## --- feat disab\n",
    "def eng_scores(chunk):\n",
    "    score_deficiencia = chunk[drop_deficiencia].sum(axis=1).astype('int8')\n",
    "    score_especifico = chunk[drop_especifico].sum(axis=1).astype('int8')\n",
    "    score_especializado = chunk[drop_especializado[1:]].sum(axis=1).astype('int8')\n",
    "    \n",
    "    return (score_deficiencia,\n",
    "            score_especifico,\n",
    "            score_especializado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- creating file 'train_1st_eng.csv'\n",
    "\n",
    "reader = pd.read_csv('train.csv', chunksize=20000)\n",
    "\n",
    "is_na = 0\n",
    "lines = 0\n",
    "with open('train_1st_eng.csv', 'w') as outFile:\n",
    "\n",
    "    for chunk in reader:\n",
    "\n",
    "        chunk.dropna(axis=0, how='all', inplace=True)\n",
    "        \n",
    "        ## -- conversão de tipos\n",
    "        chunk['NU_IDADE'] = chunk['NU_IDADE'].fillna(chunk['NU_IDADE'].mean()).astype('int8')\n",
    "        chunk['TP_STATUS_REDACAO'] = chunk['TP_STATUS_REDACAO'].fillna(0).astype('int8')\n",
    "\n",
    "        ## -- feature engineering\n",
    "        chunk['SCOR_DEFICIENCIA'], chunk['SCOR_ESPECIFICO'], chunk['SCOR_ESPECIALIZADO'] = eng_scores( chunk )\n",
    "        chunk['NU_MED_NOTAS'] = chunk[notas].mean(axis=1)\n",
    "        chunk = eng_dsoec(chunk)\n",
    "\n",
    "        ## -- eliminação de dados pouco relevantes\n",
    "        chunk.drop(np.concatenate((drop_deficiencia,\n",
    "                        drop_especifico,\n",
    "                        drop_especializado,\n",
    "                        drop_dados,\n",
    "                        drop_prova), axis=None), axis=1, inplace=True)\n",
    "        chunk.drop(['TP_LINGUA'], axis=1, inplace=True)\n",
    "\n",
    "        is_na = is_na + chunk.isna().sum(axis=0)\n",
    "        lines = lines + len(chunk)\n",
    "\n",
    "        ## -- removendo dados dos ausentes e eliminados\n",
    "        chunk = chunk[(chunk['TP_PRESENCA_CN']+chunk['TP_PRESENCA_CH']+\n",
    "                 chunk['TP_PRESENCA_LC']+chunk['TP_PRESENCA_MT']) ==4 ].copy()\n",
    "\n",
    "        ## -- removendo redações anuladas (2,3,4,6,7,8,9)\n",
    "        chunk = chunk[chunk['TP_STATUS_REDACAO']==1].copy()\n",
    "        \n",
    "        chunk.to_csv(outFile, header=None, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- identificando colunas com < 40% de missing values\n",
    "cols_train    = is_na.index\n",
    "to_read_train = is_na/lines < 0.4\n",
    "to_read_train = {A:to_read_train.index.get_loc(A) for A in to_read_train.index if to_read_train[A] == True }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- creating file 'test_1st_eng.csv'\n",
    "\n",
    "reader = pd.read_csv('test.csv', chunksize=20000)\n",
    "\n",
    "is_na = 0\n",
    "lines = 0\n",
    "with open('test_1st_eng.csv', 'w') as outFile:\n",
    "\n",
    "    for chunk in reader:\n",
    "\n",
    "        chunk.dropna(axis=0, how='all', inplace=True)\n",
    "        \n",
    "        ## -- conversão de tipos\n",
    "        chunk['NU_IDADE'] = chunk['NU_IDADE'].fillna(chunk['NU_IDADE'].mean()).astype('int8')\n",
    "        chunk['TP_STATUS_REDACAO'] = chunk['TP_STATUS_REDACAO'].fillna(0).astype('int8')\n",
    "\n",
    "        ## -- feature engineering\n",
    "        chunk['SCOR_DEFICIENCIA'], chunk['SCOR_ESPECIFICO'], chunk['SCOR_ESPECIALIZADO'] = eng_scores( chunk )\n",
    "        chunk = eng_dsoec(chunk)\n",
    "\n",
    "        ## -- eliminação de dados pouco relevantes\n",
    "        chunk.drop(np.concatenate((drop_deficiencia,\n",
    "                        drop_especifico,\n",
    "                        drop_especializado,\n",
    "                        drop_dados,\n",
    "                        drop_prova), axis=None), axis=1, inplace=True)\n",
    "        chunk.drop(['TP_LINGUA'], axis=1, inplace=True)\n",
    "\n",
    "        is_na = is_na + chunk.isna().sum(axis=0)\n",
    "        lines = lines + len(chunk)\n",
    "\n",
    "        ## -- removendo dados dos ausentes e eliminados\n",
    "        chunk = chunk[(chunk['TP_PRESENCA_CN']+chunk['TP_PRESENCA_CH']+\n",
    "                 chunk['TP_PRESENCA_LC']+chunk['TP_PRESENCA_MT']) ==4 ].copy()\n",
    "\n",
    "        ## -- removendo redações anuladas (2,3,4,6,7,8,9)\n",
    "        chunk = chunk[chunk['TP_STATUS_REDACAO']==1].copy()\n",
    "        \n",
    "        chunk.to_csv(outFile, header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- identificando colunas com < 40% de missing values\n",
    "cols_test    = is_na.index\n",
    "to_read_test = is_na/lines < 0.4\n",
    "to_read_test = {A:to_read_test.index.get_loc(A) for A in to_read_test.index if to_read_test[A] == True }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- detecção de outliers com IsolationForest\n",
    "col_idxs = [to_read_train[x] for x in \n",
    "                            ['NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_LC','NU_NOTA_MT','NU_NOTA_REDACAO'] ]\n",
    "notas = pd.read_csv( 'train_1st_eng.csv', header=None, usecols=col_idxs )\n",
    "\n",
    "std = notas.std().mean()\n",
    "avg = notas.mean().mean()\n",
    "\n",
    "cont = round(len(notas[(notas > avg+3*std)].dropna(axis=0, how='all'))/len(notas),3)\n",
    "\n",
    "random_state = np.random.RandomState(42)\n",
    "model = IsolationForest(n_estimators=100, max_samples='auto',\n",
    "                        contamination=cont,random_state=random_state)\n",
    "\n",
    "model.fit(notas)\n",
    "\n",
    "notas['anomaly_score'] = model.predict(notas)\n",
    "\n",
    "index_outliers = notas[notas['anomaly_score']==-1].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- creating files 'to_train.csv' and 'to_test.csv'\n",
    "with open('to_train.csv', 'w') as outFile:\n",
    "    to_train = pd.read_csv('train_1st_eng.csv', usecols=list(to_read_train.values()), header=None)\n",
    "    to_train.drop(index_outliers, axis=0, inplace=True)\n",
    "    to_train.columns = [x for x in cols_train if x in list(to_read_train.keys())]\n",
    "    to_train.to_csv(outFile, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('to_test.csv', 'w') as outFile:\n",
    "    to_test = pd.read_csv('test_1st_eng.csv', usecols=list(to_read_test.values()), header=None)\n",
    "    to_test.columns = [x for x in cols_test if x in list(to_read_test.keys())]\n",
    "    to_test.to_csv(outFile, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
