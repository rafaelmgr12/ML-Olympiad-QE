{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2eca808",
   "metadata": {},
   "source": [
    "# Otimizando Regressor para Predição das Notas de Cie. da Natureza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ba6d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Bibliotecas para estrutura de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## --- Funções de pre-processamento\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "## --- Bibliotecas de machine learning\n",
    "from sklearn.cluster import KMeans\n",
    "import lightgbm as lgbm\n",
    "\n",
    "## --- Funções definidas pelo usuário\n",
    "from subroutines import reduce_mem_usage\n",
    "\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3de8cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## variáveis relevantes para leitura\n",
    "\n",
    "## --- notas\n",
    "\n",
    "notas = ['NU_NOTA_CN']\n",
    "\n",
    "### --- variáveis gerais\n",
    "list_vars = np.array(['Q001','Q002', 'Q003', 'Q004', 'Q005', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011','Q012', 'Q013',\n",
    "            'Q014', 'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021','Q022', 'Q023', 'Q024', 'Q025',\n",
    "            'IN_ACESSO', 'TP_ANO_CONCLUIU','TP_SEXO', 'TP_DEPENDENCIA_ADM_ESC','TP_LINGUA',\n",
    "            'NU_IDADE', 'TP_ESCOLA', 'TP_COR_RACA', 'TP_ST_CONCLUSAO', 'IN_LIBRAS',\n",
    "            'CO_MUNICIPIO_RESIDENCIA', 'CO_ESCOLA', 'CO_MUNICIPIO_PROVA',\n",
    "            'TP_ENSINO', 'SG_UF_PROVA', 'TP_ESTADO_CIVIL', 'TP_NACIONALIDADE',\n",
    "            'IN_SEM_RECURSO', 'IN_SALA_ESPECIAL', 'SG_UF_NASCIMENTO', 'SG_UF_ESC',\n",
    "            'IN_TREINEIRO', 'IN_DEFICIT_ATENCAO', 'TP_SIT_FUNC_ESC',\n",
    "            'CO_MUNICIPIO_ESC', 'IN_LEDOR', 'IN_TEMPO_ADICIONAL',\n",
    "            'IN_DEFICIENCIA_AUDITIVA', 'TP_LOCALIZACAO_ESC', 'IN_DEFICIENCIA_MENTAL',\n",
    "            'IN_SURDEZ', 'IN_AUTISMO', 'IN_DEFICIENCIA_FISICA', 'IN_TRANSCRICAO',\n",
    "            'CO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'CO_UF_PROVA',\n",
    "            'IN_MAQUINA_BRAILE', 'TP_PRESENCA_MT', 'TP_PRESENCA_LC',\n",
    "            'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_STATUS_REDACAO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb159f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- lendo dados de treino\n",
    "reader = pd.read_csv('../input/train.csv', engine='c', chunksize=50000, \n",
    "                     nrows=350000, usecols=np.append(list_vars, notas) )\n",
    "\n",
    "df = pd.DataFrame(columns=pd.read_csv('../input/train.csv', nrows=2, \n",
    "                                      usecols=np.append(list_vars, notas)).columns)\n",
    "for chunk in reader:\n",
    "    df = pd.concat([df ,reduce_mem_usage(chunk)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef5e3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NU_IDADE'] = df['NU_IDADE'].fillna(df['NU_IDADE'].mode().iloc[0])\n",
    "df['CO_MUNICIPIO_NASCIMENTO'] = df['CO_MUNICIPIO_NASCIMENTO'].fillna(df['CO_MUNICIPIO_PROVA'])\n",
    "df['CO_MUNICIPIO_ESC'] = df['CO_MUNICIPIO_ESC'].fillna(df['CO_MUNICIPIO_PROVA'])\n",
    "df['TP_SIT_FUNC_ESC'] = df['TP_SIT_FUNC_ESC'].fillna(1)\n",
    "df['TP_LOCALIZACAO_ESC'] = df['TP_LOCALIZACAO_ESC'].fillna(1)\n",
    "df['SG_UF_ESC'] = df['SG_UF_ESC'].fillna(df['SG_UF_NASCIMENTO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5769b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idhm_ifdm = pd.read_csv('https://raw.githubusercontent.com/rrpronaldo/quality_education/main/dataset_idhm_ifdm.csv')\n",
    "dict_idhm = dict(zip(df_idhm_ifdm.CO_MUNICIPIO,df_idhm_ifdm.VR_IDHM))\n",
    "df['VR_IDHM'] = df.CO_MUNICIPIO_RESIDENCIA.map(dict_idhm)\n",
    "\n",
    "df_ifdm = pd.read_csv('https://raw.githubusercontent.com/rrpronaldo/quality_education/main/dataset_idhm_ifdm.csv')\n",
    "dict_ifdm = dict(zip(df_ifdm.CO_MUNICIPIO,df_ifdm.IFDM_2010))\n",
    "df['VR_IFDM'] = df.CO_MUNICIPIO_RESIDENCIA.map(dict_ifdm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73360e80",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8bf1018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## --- variáveis para codificar\n",
    "list_toenc = np.array(['Q001','Q002', 'Q003', 'Q004', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011','Q012', 'Q013',\n",
    "            'Q014', 'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021','Q022', 'Q023', 'Q024', 'Q025',\n",
    "            'CO_MUNICIPIO_RESIDENCIA', 'CO_ESCOLA', 'CO_MUNICIPIO_PROVA',\n",
    "            'SG_UF_PROVA', 'SG_UF_NASCIMENTO', 'SG_UF_ESC','TP_LINGUA','TP_SEXO',\n",
    "            'CO_MUNICIPIO_ESC', 'CO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'CO_UF_PROVA'])\n",
    "\n",
    "## --- variáveis mais relevantes para matemática\n",
    "ft_cn = np.array(['TP_PRESENCA_CN', 'TP_STATUS_REDACAO', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'Q006', 'NU_IDADE', 'TP_ST_CONCLUSAO', 'Q024', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'Q008', 'Q002', 'Q010', 'Q003', 'TP_DEPENDENCIA_ADM_ESC', 'CO_ESCOLA', 'IN_TREINEIRO', 'TP_LINGUA', 'Q018', 'Q004', 'Q001', 'Q025', 'Q022', 'Q007', 'CO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'TP_SIT_FUNC_ESC', 'Q013', 'CO_MUNICIPIO_RESIDENCIA', 'CO_MUNICIPIO_ESC', 'Q016', 'SG_UF_ESC', 'Q009', 'TP_ENSINO', 'Q014', 'CO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'TP_LOCALIZACAO_ESC', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'Q019', 'TP_COR_RACA', 'Q017', 'Q021', 'Q023', 'Q005', 'SG_UF_PROVA', 'SG_UF_NASCIMENTO', 'Q020', 'Q012', 'Q011', 'IN_TEMPO_ADICIONAL', 'TP_NACIONALIDADE','Q015'])\n",
    "\n",
    "#ft_clust = ['TP_PRESENCA_CN','Q006', 'Q024', 'Q008','Q002', 'Q010', 'Q003']\n",
    "ft_clust = ['TP_PRESENCA_CN', 'Q006', 'NU_IDADE', 'Q024', 'TP_ESCOLA', 'Q004', 'Q002', 'Q003']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa6d2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- encoder\n",
    "is_to_enc = 0\n",
    "if is_to_enc == 1:\n",
    "    ##encoding\n",
    "    enc1 = reduce_mem_usage( pd.read_csv('../input/train.csv', engine='c',\n",
    "                                       usecols=list_toenc) )\n",
    "    enc2 = reduce_mem_usage( pd.read_csv('../input/test.csv', engine='c',\n",
    "                                       usecols=list_toenc) )\n",
    "\n",
    "    enc = pd.concat([enc1,enc2])\n",
    "    del enc1, enc2\n",
    "    encoders = []\n",
    "    for coluna in list_toenc:\n",
    "        if enc[coluna].isna().any() == True:\n",
    "            encoders.append( LabelEncoder().fit( list(set(enc[coluna].astype(str).fillna(\"missing\").replace(\"nan\", \"missing\").unique().tolist())) ) )\n",
    "        else:\n",
    "            encoders.append( LabelEncoder().fit( list(set(enc[coluna].astype(str).unique().tolist())) ) )\n",
    "    del enc\n",
    "    ## saving encoders\n",
    "    for enc, n in zip( encoders, np.arange(len(encoders)) ):\n",
    "        np.save('./Encoders/natureza/classes_%s.npy' % n, enc.classes_)\n",
    "else:\n",
    "    encoders = []\n",
    "    for n in np.arange(len(list_toenc)):\n",
    "        enc = LabelEncoder()\n",
    "        enc.classes_ = np.load('./Encoders/natureza/classes_%s.npy' % n)\n",
    "        encoders.append(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64792f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- substitui notas missing por zero\n",
    "for coluna in notas:\n",
    "    df[coluna] = df[coluna].fillna(0)\n",
    "    \n",
    "## --- substitui valores NaN (variáveis numéricas)  por inteiro arbitrário \n",
    "\n",
    "for coluna in df[list_vars].loc[:2,~df[list_vars].columns.isin(list_toenc)].columns:\n",
    "    df[coluna] = df[coluna].fillna(-32768).astype('int16')\n",
    "    \n",
    "i=0\n",
    "for coluna in list_toenc:\n",
    "    df[coluna] = df[coluna].astype(str).fillna(\"missing\").replace(\"nan\", \"missing\").astype('category')\n",
    "    df[coluna] = encoders[i].transform(df[coluna])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52ca9ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- redução de cardinalidade\n",
    "#df['NU_IDADE'] = df['NU_IDADE'].apply(lambda x: x if x<25 else 25)\n",
    "\n",
    "df['Q006'] = df['Q006'].apply(lambda x: x if x<11 else 11)\n",
    "\n",
    "\n",
    "\"\"\"df['Q004'] = df['Q004'].apply(lambda x: 0 if x==0 else\n",
    "                                        1 if (x==1) | (x==2) | (x==5) else x-1)\"\"\"\n",
    "\n",
    "df['Q002'] = df['Q002'].apply(lambda x: 1 if (x==1) | (x==7) else x)\n",
    "\n",
    "#df['TP_ANO_CONCLUIU'] = df['TP_ANO_CONCLUIU'].apply(lambda x: x if x<3 else 3)\n",
    "\n",
    "df['Q003'] = df['Q003'].apply(lambda x: 0 if x==0 else\n",
    "                                        1 if (x==1) | (x==2) | (x==5) else x-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccbccb9",
   "metadata": {},
   "source": [
    "### Treino do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fcb528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- instanciamento do agrupador\n",
    "nclust = 3\n",
    "model = make_pipeline(StandardScaler(), KMeans(n_clusters=nclust))\n",
    "model.fit(df[ft_clust])\n",
    "\n",
    "# atribui cada amostra a um grupo\n",
    "df['CLUSTER'] = model.predict(df[ft_clust])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1fddd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_cn = make_pipeline(StandardScaler(), lgbm.LGBMRegressor(boosting_type='gbdt', \n",
    "                                                                   learning_rate=0.1, \n",
    "                                                                   max_depth=-1, \n",
    "                                                                   n_estimators=480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53e0f877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.71941317263984"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "\n",
    "xval_err = 0\n",
    "y = df['NU_NOTA_CN']\n",
    "for train_index, test_index in kf.split(df[np.append(ft_cn,['CLUSTER','VR_IFDM','VR_IDHM'])]):\n",
    "    X_train, X_test = df[np.append(ft_cn,['CLUSTER','VR_IFDM','VR_IDHM'])].iloc[train_index,:], df[np.append(ft_cn,['CLUSTER','VR_IFDM','VR_IDHM'])].iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    regressor_cn.fit(X_train, y_train)\n",
    "    y_pred = pd.Series(regressor_cn.predict(X_test))\n",
    "    #y_pred.iloc[X_test[X_test['TP_PRESENCA_CH']!=1].reset_index(drop=True).index] = 0\n",
    "    xval_err += np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "rmse_5cv = xval_err/5\n",
    "rmse_5cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5757bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[np.append(ft_cn,'CLUSTER')],\n",
    "                                                    df['NU_NOTA_CN'],\n",
    "                                                    random_state=42)\n",
    "\n",
    "regressor_cn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pd.Series(regressor_cn.predict(X_test))\n",
    "#y_pred.iloc[X_test[X_test['TP_PRESENCA_CN']!=1].reset_index(drop=True).index] = 0\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6406f396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## --- fit do modelo e gravação dos parâmetros em arquivo\\nregressor_cn.fit(df[np.append(ft_cn, 'CLUSTER')], \\n                 df['NU_NOTA_CN'])\\npickle.dump(model, open('./models/natureza.sav', 'wb'))\\n\\ndel df\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"## --- fit do modelo e gravação dos parâmetros em arquivo\n",
    "regressor_cn.fit(df[np.append(ft_cn, 'CLUSTER')], \n",
    "                 df['NU_NOTA_CN'])\n",
    "pickle.dump(model, open('./models/natureza.sav', 'wb'))\n",
    "\n",
    "del df\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce841622",
   "metadata": {},
   "source": [
    "## Predição das Notas de Cie. da Natureza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e60ed5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pd.read_csv('../input/test.csv', engine='c', usecols=['NU_INSCRICAO'])\n",
    "df_cn = reduce_mem_usage( pd.read_csv('../input/test.csv', engine='c', usecols=ft_cn) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "039608be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- substitui valores NaN (variáveis numéricas)  por inteiro arbitrário \n",
    "\n",
    "for coluna in df_cn.loc[:2,~df_cn.columns.isin(list_toenc)].columns:\n",
    "    df_cn[coluna] = df_cn[coluna].fillna(-32768).astype('int16')\n",
    "    \n",
    "i=0\n",
    "for coluna in list_toenc:\n",
    "    df_cn[coluna] = df_cn[coluna].astype(str).fillna(\"missing\").replace(\"nan\", \"missing\").astype('category')\n",
    "    df_cn[coluna] = encoders[i].transform(df_cn[coluna])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fcb9a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- redução de cardinalidade\n",
    "df['NU_IDADE'] = df['NU_IDADE'].apply(lambda x: x if x<25 else 25)\n",
    "\n",
    "df['Q006'] = df['Q006'].apply(lambda x: x if x<11 else 11)\n",
    "\n",
    "\n",
    "df['Q004'] = df['Q004'].apply(lambda x: 0 if x==0 else\n",
    "                                        1 if (x==1) | (x==2) | (x==5) else x-1)\n",
    "\n",
    "df['Q002'] = df['Q002'].apply(lambda x: 1 if (x==1) | (x==7) else x)\n",
    "\n",
    "df['TP_ANO_CONCLUIU'] = df['TP_ANO_CONCLUIU'].apply(lambda x: x if x<3 else 3)\n",
    "\n",
    "df['Q003'] = df['Q003'].apply(lambda x: 0 if x==0 else\n",
    "                                        1 if (x==1) | (x==2) | (x==5) else x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2390ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## clusterização\n",
    "df_cn['CLUSTER'] = model.predict(df_cn[ft_clust])\n",
    "## predição\n",
    "submissions['NU_NOTA_CN'] = regressor_cn.predict(df_cn[np.append(ft_cn,'CLUSTER')])\n",
    "submissions['NU_NOTA_CN'].iloc[df_cn[df_cn['TP_PRESENCA_CN']!=1].index] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af811e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.to_csv('./submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcbe00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cn['NU_IDADE'] = df_cn['NU_IDADE'].fillna(df_cn['NU_IDADE'].mode().iloc[0])\n",
    "df_cn['CO_MUNICIPIO_NASCIMENTO'] = df_cn['CO_MUNICIPIO_NASCIMENTO'].fillna(df_cn['CO_MUNICIPIO_PROVA'])\n",
    "df_cn['CO_MUNICIPIO_ESC'] = df_cn['CO_MUNICIPIO_ESC'].fillna(df_cn['CO_MUNICIPIO_PROVA'])\n",
    "df_cn['TP_SIT_FUNC_ESC'] = df_cn['TP_SIT_FUNC_ESC'].fillna(1)\n",
    "df_cn['TP_LOCALIZACAO_ESC'] = df_cn['TP_LOCALIZACAO_ESC'].fillna(1)\n",
    "df_cn['SG_UF_ESC'] = df_cn['SG_UF_ESC'].fillna(df_cn['SG_UF_NASCIMENTO'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
