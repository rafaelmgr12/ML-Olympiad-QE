{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2eca808",
   "metadata": {},
   "source": [
    "# Otimizando Regressor para Predição das Notas de Cie. Humanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba6d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Bibliotecas para estrutura de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## --- Funções de pre-processamento\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "\n",
    "## --- Bibliotecas de machine learning\n",
    "from sklearn.cluster import KMeans\n",
    "import lightgbm as lgbm\n",
    "\n",
    "## --- Funções definidas pelo usuário\n",
    "from subroutines import reduce_mem_usage\n",
    "\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de8cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## variáveis relevantes para leitura\n",
    "\n",
    "## --- notas\n",
    "\n",
    "notas = ['NU_NOTA_CH']\n",
    "\n",
    "### --- variáveis gerais\n",
    "list_vars = np.array(['Q001','Q002', 'Q003', 'Q004', 'Q005', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011','Q012', 'Q013',\n",
    "            'Q014', 'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021','Q022', 'Q023', 'Q024', 'Q025',\n",
    "            'IN_ACESSO', 'TP_ANO_CONCLUIU','TP_SEXO', 'TP_DEPENDENCIA_ADM_ESC','TP_LINGUA',\n",
    "            'NU_IDADE', 'TP_ESCOLA', 'TP_COR_RACA', 'TP_ST_CONCLUSAO', 'IN_LIBRAS',\n",
    "            'CO_MUNICIPIO_RESIDENCIA', 'CO_ESCOLA', 'CO_MUNICIPIO_PROVA',\n",
    "            'TP_ENSINO', 'SG_UF_PROVA', 'TP_ESTADO_CIVIL', 'TP_NACIONALIDADE',\n",
    "            'IN_SEM_RECURSO', 'IN_SALA_ESPECIAL', 'SG_UF_NASCIMENTO', 'SG_UF_ESC',\n",
    "            'IN_TREINEIRO', 'IN_DEFICIT_ATENCAO', 'TP_SIT_FUNC_ESC',\n",
    "            'CO_MUNICIPIO_ESC', 'IN_LEDOR', 'IN_TEMPO_ADICIONAL',\n",
    "            'IN_DEFICIENCIA_AUDITIVA', 'TP_LOCALIZACAO_ESC', 'IN_DEFICIENCIA_MENTAL',\n",
    "            'IN_SURDEZ', 'IN_AUTISMO', 'IN_DEFICIENCIA_FISICA', 'IN_TRANSCRICAO',\n",
    "            'CO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'CO_UF_PROVA',\n",
    "            'IN_MAQUINA_BRAILE', 'TP_PRESENCA_MT', 'TP_PRESENCA_LC',\n",
    "            'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_STATUS_REDACAO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb159f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- lendo dados de treino\n",
    "reader = pd.read_csv('../input/train.csv', engine='c', chunksize=50000, \n",
    "                     nrows=500000, usecols=np.append(list_vars, notas) )\n",
    "\n",
    "df = pd.DataFrame(columns=pd.read_csv('../input/train.csv', nrows=2, \n",
    "                                      usecols=np.append(list_vars, notas)).columns)\n",
    "for chunk in reader:\n",
    "    df = pd.concat([df ,reduce_mem_usage(chunk)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "288ee2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NU_IDADE'] = df['NU_IDADE'].fillna(df['NU_IDADE'].mode().iloc[0])\n",
    "df['CO_MUNICIPIO_NASCIMENTO'] = df['CO_MUNICIPIO_NASCIMENTO'].fillna(df['CO_MUNICIPIO_PROVA'])\n",
    "df['CO_MUNICIPIO_ESC'] = df['CO_MUNICIPIO_ESC'].fillna(df['CO_MUNICIPIO_PROVA'])\n",
    "df['TP_SIT_FUNC_ESC'] = df['TP_SIT_FUNC_ESC'].fillna(1)\n",
    "df['TP_LOCALIZACAO_ESC'] = df['TP_LOCALIZACAO_ESC'].fillna(1)\n",
    "df['SG_UF_ESC'] = df['SG_UF_ESC'].fillna(df['SG_UF_NASCIMENTO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94a03c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idhm_ifdm = pd.read_csv('https://raw.githubusercontent.com/rrpronaldo/quality_education/main/dataset_idhm_ifdm.csv')\n",
    "dict_idhm = dict(zip(df_idhm_ifdm.CO_MUNICIPIO,df_idhm_ifdm.VR_IDHM))\n",
    "df['VR_IDHM'] = df.CO_MUNICIPIO_RESIDENCIA.map(dict_idhm)\n",
    "\n",
    "df_ifdm = pd.read_csv('https://raw.githubusercontent.com/rrpronaldo/quality_education/main/dataset_idhm_ifdm.csv')\n",
    "dict_ifdm = dict(zip(df_ifdm.CO_MUNICIPIO,df_ifdm.IFDM_2010))\n",
    "df['VR_IFDM'] = df.CO_MUNICIPIO_RESIDENCIA.map(dict_ifdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1cff4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73360e80",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8bf1018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## --- variáveis para codificar\n",
    "list_toenc = np.array(['Q001','Q002', 'Q003', 'Q004', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011','Q012', 'Q013',\n",
    "            'Q014', 'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021','Q022', 'Q023', 'Q024', 'Q025',\n",
    "            'CO_MUNICIPIO_RESIDENCIA', 'CO_ESCOLA', 'CO_MUNICIPIO_PROVA',\n",
    "            'SG_UF_PROVA', 'SG_UF_NASCIMENTO', 'SG_UF_ESC','TP_LINGUA','TP_SEXO',\n",
    "            'CO_MUNICIPIO_ESC', 'CO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'CO_UF_PROVA'])\n",
    "\n",
    "## --- variáveis mais relevantes para cie. humanas\n",
    "ft_ch = np.array(['TP_PRESENCA_CH',  'TP_PRESENCA_MT', 'TP_PRESENCA_CN', 'Q006', 'Q024', 'NU_IDADE', 'TP_ST_CONCLUSAO', 'Q008', 'TP_ANO_CONCLUIU', 'Q002', 'TP_LINGUA', 'TP_ESCOLA', 'Q004', 'Q003', 'Q018', 'TP_DEPENDENCIA_ADM_ESC', 'Q001', 'IN_TREINEIRO', 'Q019', 'Q007', 'Q010', 'Q016', 'CO_ESCOLA', 'Q021', 'TP_ENSINO', 'TP_SIT_FUNC_ESC', 'SG_UF_ESC', 'CO_MUNICIPIO_PROVA', 'Q014', 'CO_MUNICIPIO_ESC', 'Q025', 'CO_MUNICIPIO_RESIDENCIA', 'Q013', 'CO_UF_PROVA', 'Q022', 'TP_COR_RACA', 'TP_LOCALIZACAO_ESC', 'Q023', 'Q017', 'CO_UF_NASCIMENTO', 'Q009', 'Q005', 'CO_MUNICIPIO_NASCIMENTO', 'Q011', 'TP_ESTADO_CIVIL', 'SG_UF_PROVA', 'SG_UF_NASCIMENTO', 'Q015', 'TP_NACIONALIDADE', 'IN_DEFICIT_ATENCAO', 'Q020','Q012','TP_SEXO','IN_SEM_RECURSO'])\n",
    "\n",
    "#ft_clust = ['Q006', 'Q024', 'Q008','Q002']\n",
    "ft_clust = ['TP_PRESENCA_CH', 'Q006', 'NU_IDADE', 'Q024', 'TP_ESCOLA', 'Q004', 'Q002', 'Q003']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa6d2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- encoder\n",
    "is_to_enc = 0\n",
    "if is_to_enc == 1:\n",
    "    ##encoding\n",
    "    enc1 = reduce_mem_usage( pd.read_csv('../input/train.csv', engine='c',\n",
    "                                       usecols=list_toenc) )\n",
    "    enc2 = reduce_mem_usage( pd.read_csv('../input/test.csv', engine='c',\n",
    "                                       usecols=list_toenc) )\n",
    "\n",
    "    enc = pd.concat([enc1,enc2])\n",
    "    del enc1, enc2\n",
    "    encoders = []\n",
    "    for coluna in list_toenc:\n",
    "        if enc[coluna].isna().any() == True:\n",
    "            encoders.append( LabelEncoder().fit( list(set(enc[coluna].astype(str).fillna(\"missing\").replace(\"nan\", \"missing\").unique().tolist())) ) )\n",
    "        else:\n",
    "            encoders.append( LabelEncoder().fit( list(set(enc[coluna].astype(str).unique().tolist())) ) )\n",
    "    del enc\n",
    "    ## saving encoders\n",
    "    for enc, n in zip( encoders, np.arange(len(encoders)) ):\n",
    "        np.save('./Encoders/humanas/classes_%s.npy' % n, enc.classes_)\n",
    "else:\n",
    "    encoders = []\n",
    "    for n in np.arange(len(list_toenc)):\n",
    "        enc = LabelEncoder()\n",
    "        enc.classes_ = np.load('./Encoders/humanas/classes_%s.npy' % n)\n",
    "        encoders.append(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64792f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- substitui notas missing por zero\n",
    "for coluna in notas:\n",
    "    df[coluna] = df[coluna].fillna(0)\n",
    "    \n",
    "## --- substitui valores NaN (variáveis numéricas)  por inteiro arbitrário \n",
    "\n",
    "for coluna in df[list_vars].loc[:2,~df[list_vars].columns.isin(list_toenc)].columns:\n",
    "    df[coluna] = df[coluna].fillna(-32768).astype('int16')\n",
    "    \n",
    "i=0\n",
    "for coluna in list_toenc:\n",
    "    df[coluna] = df[coluna].astype(str).fillna(\"missing\").replace(\"nan\", \"missing\").astype('category')\n",
    "    df[coluna] = encoders[i].transform(df[coluna])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52ca9ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- redução de cardinalidade\n",
    "#df['NU_IDADE'] = df['NU_IDADE'].apply(lambda x: x if x<25 else 25)\n",
    "\n",
    "#df['Q006'] = df['Q006'].apply(lambda x: x if x<11 else 11)\n",
    "\n",
    "\n",
    "\"\"\"df['Q004'] = df['Q004'].apply(lambda x: 0 if x==0 else\n",
    "                                        1 if (x==1) | (x==2) | (x==5) else x-1)\"\"\"\n",
    "\n",
    "df['Q002'] = df['Q002'].apply(lambda x: 0 if (x==0) | (x==7) else x)\n",
    "\n",
    "#df['TP_ANO_CONCLUIU'] = df['TP_ANO_CONCLUIU'].apply(lambda x: x if x<5 else 5)\n",
    "\n",
    "df['Q003'] = df['Q003'].apply(lambda x: 0 if x==0 else\n",
    "                                        1 if (x==1) | (x==2) | (x==5) else x-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccbccb9",
   "metadata": {},
   "source": [
    "### Treino do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fcb528f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## --- instanciamento do agrupador\\nnclust = 4\\nmodel = make_pipeline(StandardScaler(), KMeans(n_clusters=nclust))\\nmodel.fit(df[ft_clust])\\n\\n# atribui cada amostra a um grupo\\ndf['CLUSTER'] = model.predict(df[ft_clust])\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"## --- instanciamento do agrupador\n",
    "nclust = 4\n",
    "model = make_pipeline(StandardScaler(), KMeans(n_clusters=nclust))\n",
    "model.fit(df[ft_clust])\n",
    "\n",
    "# atribui cada amostra a um grupo\n",
    "df['CLUSTER'] = model.predict(df[ft_clust])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1fddd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_ch = make_pipeline(StandardScaler(), lgbm.LGBMRegressor(boosting_type='gbdt', \n",
    "                                                                   learning_rate=0.11, \n",
    "                                                                   max_depth=-1, \n",
    "                                                                   n_estimators=350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c27d400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.24246606488751"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"kf = KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "\n",
    "xval_err = 0\n",
    "y = df['NU_NOTA_CH']\n",
    "for train_index, test_index in kf.split(df[np.append(ft_ch,'CLUSTER')]):\n",
    "    X_train, X_test = df[np.append(ft_ch,'CLUSTER')].iloc[train_index,:], df[np.append(ft_ch,'CLUSTER')].iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    regressor_ch.fit(X_train, y_train)\n",
    "    y_pred = pd.Series(regressor_ch.predict(X_test))\n",
    "    #y_pred.iloc[X_test[X_test['TP_PRESENCA_CH']!=1].reset_index(drop=True).index] = 0\n",
    "    xval_err += np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "rmse_5cv = xval_err/5\n",
    "rmse_5cv\"\"\"\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "\n",
    "xval_err = 0\n",
    "y = df['NU_NOTA_CH']\n",
    "for train_index, test_index in kf.split(df[np.append(ft_ch,['VR_IFDM','VR_IDHM','QART'])]):\n",
    "    X_train, X_test = df[np.append(ft_ch,['VR_IFDM','VR_IDHM','QART'])].iloc[train_index,:], df[np.append(ft_ch,['VR_IFDM','VR_IDHM'])].iloc[test_index,:]\n",
    "    X_test['QART'] = clf_ch.predict(X_test)\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    regressor_ch.fit(X_train, y_train)\n",
    "    y_pred = pd.Series(regressor_ch.predict(X_test))\n",
    "    #y_pred.iloc[X_test[X_test['TP_PRESENCA_CH']!=1].reset_index(drop=True).index] = 0\n",
    "    xval_err += np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "rmse_5cv = xval_err/5\n",
    "rmse_5cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df817f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.91458439097978"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[np.append(ft_ch,'CLUSTER')],\n",
    "                                                    df['NU_NOTA_CH'],\n",
    "                                                    random_state=42)\n",
    "\n",
    "regressor_ch.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pd.Series(regressor_ch.predict(X_test))\n",
    "#y_pred.iloc[X_test[X_test['TP_PRESENCA_CN']!=1].reset_index(drop=True).index] = 0\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6406f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## --- fit do modelo e gravação dos parâmetros em arquivo\n",
    "regressor_ch.fit(df[np.append(ft_ch,\"CLUSTER\")], df['NU_NOTA_CH'])\n",
    "pickle.dump(model, open('./models/humanas.sav', 'wb'))\n",
    "\n",
    "del df\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea3491df",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4300/3428378040.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/train_csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NU_NOTA_REDACAO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_SparseArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module 'pandas' has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'read'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9323b7d",
   "metadata": {},
   "source": [
    "## Predição das Nota de Cie. Humanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3575093",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pd.read_csv('./submissions.csv', engine='c')\n",
    "df_ch = reduce_mem_usage( pd.read_csv('../input/test.csv', engine='c', usecols=list_vars) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13ddb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- substitui valores NaN (variáveis numéricas)  por inteiro arbitrário \n",
    "for coluna in df_ch.loc[:2,~df_ch.columns.isin(list_toenc)].columns:\n",
    "    df_ch[coluna] = df_ch[coluna].fillna(-32768).astype('int16')\n",
    "    \n",
    "i=0\n",
    "for coluna in list_toenc:\n",
    "    df_ch[coluna] = df_ch[coluna].astype(str).fillna(\"missing\").replace(\"nan\", \"missing\").astype('category')\n",
    "    df_ch[coluna] = encoders[i].transform(df_ch[coluna])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5082920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- redução de cardinalidade\n",
    "df_ch['NU_IDADE'] = df_ch['NU_IDADE'].apply(lambda x: x if x<25 else 25)\n",
    "\n",
    "df_ch['Q006'] = df_ch['Q006'].apply(lambda x: x if x<11 else 11)\n",
    "\n",
    "\n",
    "df_ch['Q004'] = df_ch['Q004'].apply(lambda x: 0 if x==0 else\n",
    "                                        1 if (x==1) | (x==2) | (x==5) else x-1)\n",
    "\n",
    "df_ch['Q002'] = df_ch['Q002'].apply(lambda x: 0 if (x==0) | (x==7) else x)\n",
    "\n",
    "df_ch['TP_ANO_CONCLUIU'] = df_ch['TP_ANO_CONCLUIU'].apply(lambda x: x if x<5 else 5)\n",
    "\n",
    "df_ch['Q003'] = df_ch['Q003'].apply(lambda x: 0 if x==0 else\n",
    "                                        1 if (x==1) | (x==2) | (x==5) else x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85f6f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## clusterização\n",
    "df_ch['CLUSTER'] = model.predict(df_ch[ft_clust])\n",
    "## predição\n",
    "submissions['NU_NOTA_CH'] = regressor_ch.predict(df_ch[np.append(ft_ch,'CLUSTER')])\n",
    "submissions['NU_NOTA_CH'].iloc[df_ch[df_ch['TP_PRESENCA_CH']!=1].index] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7cc2726",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.to_csv('./submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c51c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch['NU_IDADE'] = df_ch['NU_IDADE'].fillna(df_ch['NU_IDADE'].mode().iloc[0])\n",
    "df_ch['CO_MUNICIPIO_NASCIMENTO'] = df_ch['CO_MUNICIPIO_NASCIMENTO'].fillna(df_ch['CO_MUNICIPIO_PROVA'])\n",
    "df_ch['CO_MUNICIPIO_ESC'] = df_ch['CO_MUNICIPIO_ESC'].fillna(df_ch['CO_MUNICIPIO_PROVA'])\n",
    "df_ch['TP_SIT_FUNC_ESC'] = df_ch['TP_SIT_FUNC_ESC'].fillna(1)\n",
    "df_ch['TP_LOCALIZACAO_ESC'] = df_ch['TP_LOCALIZACAO_ESC'].fillna(1)\n",
    "df_ch['SG_UF_ESC'] = df_ch['SG_UF_ESC'].fillna(df_ch['SG_UF_NASCIMENTO'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
