{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2eca808",
   "metadata": {},
   "source": [
    "# Otimizando Regressor LGBM para Predição das Notas de Redação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ba6d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Bibliotecas para estrutura de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## --- Funções de pre-processamento\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "## --- Bibliotecas de machine learning\n",
    "from sklearn.cluster import KMeans\n",
    "import lightgbm as lgbm\n",
    "\n",
    "## --- Funções definidas pelo usuário\n",
    "from subroutines import reduce_mem_usage\n",
    "\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3de8cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## variáveis relevantes para leitura\n",
    "\n",
    "## --- notas\n",
    "\n",
    "notas = ['NU_NOTA_REDACAO']\n",
    "\n",
    "### --- variáveis gerais\n",
    "list_vars = np.array(['Q001','Q002', 'Q003', 'Q004', 'Q005', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011','Q012', 'Q013',\n",
    "            'Q014', 'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021','Q022', 'Q023', 'Q024', 'Q025',\n",
    "            'IN_ACESSO', 'TP_ANO_CONCLUIU','TP_SEXO', 'TP_DEPENDENCIA_ADM_ESC','TP_LINGUA',\n",
    "            'NU_IDADE', 'TP_ESCOLA', 'TP_COR_RACA', 'TP_ST_CONCLUSAO', 'IN_LIBRAS',\n",
    "            'CO_MUNICIPIO_RESIDENCIA', 'CO_ESCOLA', 'CO_MUNICIPIO_PROVA',\n",
    "            'TP_ENSINO', 'SG_UF_PROVA', 'TP_ESTADO_CIVIL', 'TP_NACIONALIDADE',\n",
    "            'IN_SEM_RECURSO', 'IN_SALA_ESPECIAL', 'SG_UF_NASCIMENTO', 'SG_UF_ESC',\n",
    "            'IN_TREINEIRO', 'IN_DEFICIT_ATENCAO', 'TP_SIT_FUNC_ESC',\n",
    "            'CO_MUNICIPIO_ESC', 'IN_LEDOR', 'IN_TEMPO_ADICIONAL',\n",
    "            'IN_DEFICIENCIA_AUDITIVA', 'TP_LOCALIZACAO_ESC', 'IN_DEFICIENCIA_MENTAL',\n",
    "            'IN_SURDEZ', 'IN_AUTISMO', 'IN_DEFICIENCIA_FISICA', 'IN_TRANSCRICAO',\n",
    "            'CO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'CO_UF_PROVA',\n",
    "            'IN_MAQUINA_BRAILE', 'TP_PRESENCA_MT', 'TP_PRESENCA_LC',\n",
    "            'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_STATUS_REDACAO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb159f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- lendo dados de treino\n",
    "reader = pd.read_csv('../input/train.csv', engine='c', chunksize=50000, \n",
    "                     nrows=350000, usecols=np.append(list_vars, notas) )\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=pd.read_csv('../input/train.csv', nrows=2, \n",
    "                                      usecols=np.append(list_vars, notas)).columns)\n",
    "\n",
    "\n",
    "for chunk in reader:\n",
    "    df = pd.concat([df ,reduce_mem_usage(chunk)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c529e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NU_IDADE'] = df['NU_IDADE'].fillna(df['NU_IDADE'].mode().iloc[0])\n",
    "df['CO_MUNICIPIO_NASCIMENTO'] = df['CO_MUNICIPIO_NASCIMENTO'].fillna(df['CO_MUNICIPIO_PROVA'])\n",
    "df['CO_MUNICIPIO_ESC'] = df['CO_MUNICIPIO_ESC'].fillna(df['CO_MUNICIPIO_PROVA'])\n",
    "df['TP_SIT_FUNC_ESC'] = df['TP_SIT_FUNC_ESC'].fillna(1)\n",
    "df['TP_LOCALIZACAO_ESC'] = df['TP_LOCALIZACAO_ESC'].fillna(1)\n",
    "df['SG_UF_ESC'] = df['SG_UF_ESC'].fillna(df['SG_UF_NASCIMENTO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04ed1bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CO_MUNICIPIO_RESIDENCIA</th>\n",
       "      <td>CO_MUNICIPIO_RESIDENCIA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NU_IDADE</th>\n",
       "      <td>NU_IDADE</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_SEXO</th>\n",
       "      <td>TP_SEXO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_ESTADO_CIVIL</th>\n",
       "      <td>TP_ESTADO_CIVIL</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_COR_RACA</th>\n",
       "      <td>TP_COR_RACA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_NACIONALIDADE</th>\n",
       "      <td>TP_NACIONALIDADE</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO_MUNICIPIO_NASCIMENTO</th>\n",
       "      <td>CO_MUNICIPIO_NASCIMENTO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO_UF_NASCIMENTO</th>\n",
       "      <td>CO_UF_NASCIMENTO</td>\n",
       "      <td>2.870857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SG_UF_NASCIMENTO</th>\n",
       "      <td>SG_UF_NASCIMENTO</td>\n",
       "      <td>2.870857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_ST_CONCLUSAO</th>\n",
       "      <td>TP_ST_CONCLUSAO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_ANO_CONCLUIU</th>\n",
       "      <td>TP_ANO_CONCLUIU</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_ESCOLA</th>\n",
       "      <td>TP_ESCOLA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_ENSINO</th>\n",
       "      <td>TP_ENSINO</td>\n",
       "      <td>43.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_TREINEIRO</th>\n",
       "      <td>IN_TREINEIRO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO_ESCOLA</th>\n",
       "      <td>CO_ESCOLA</td>\n",
       "      <td>77.505714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO_MUNICIPIO_ESC</th>\n",
       "      <td>CO_MUNICIPIO_ESC</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SG_UF_ESC</th>\n",
       "      <td>SG_UF_ESC</td>\n",
       "      <td>2.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_DEPENDENCIA_ADM_ESC</th>\n",
       "      <td>TP_DEPENDENCIA_ADM_ESC</td>\n",
       "      <td>77.505714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_LOCALIZACAO_ESC</th>\n",
       "      <td>TP_LOCALIZACAO_ESC</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_SIT_FUNC_ESC</th>\n",
       "      <td>TP_SIT_FUNC_ESC</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_SURDEZ</th>\n",
       "      <td>IN_SURDEZ</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_DEFICIENCIA_AUDITIVA</th>\n",
       "      <td>IN_DEFICIENCIA_AUDITIVA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_DEFICIENCIA_FISICA</th>\n",
       "      <td>IN_DEFICIENCIA_FISICA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_DEFICIENCIA_MENTAL</th>\n",
       "      <td>IN_DEFICIENCIA_MENTAL</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_DEFICIT_ATENCAO</th>\n",
       "      <td>IN_DEFICIT_ATENCAO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_AUTISMO</th>\n",
       "      <td>IN_AUTISMO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_SEM_RECURSO</th>\n",
       "      <td>IN_SEM_RECURSO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_LEDOR</th>\n",
       "      <td>IN_LEDOR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_ACESSO</th>\n",
       "      <td>IN_ACESSO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_TRANSCRICAO</th>\n",
       "      <td>IN_TRANSCRICAO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_LIBRAS</th>\n",
       "      <td>IN_LIBRAS</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_TEMPO_ADICIONAL</th>\n",
       "      <td>IN_TEMPO_ADICIONAL</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_MAQUINA_BRAILE</th>\n",
       "      <td>IN_MAQUINA_BRAILE</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_SALA_ESPECIAL</th>\n",
       "      <td>IN_SALA_ESPECIAL</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO_MUNICIPIO_PROVA</th>\n",
       "      <td>CO_MUNICIPIO_PROVA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO_UF_PROVA</th>\n",
       "      <td>CO_UF_PROVA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SG_UF_PROVA</th>\n",
       "      <td>SG_UF_PROVA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_PRESENCA_CN</th>\n",
       "      <td>TP_PRESENCA_CN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_PRESENCA_CH</th>\n",
       "      <td>TP_PRESENCA_CH</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_PRESENCA_LC</th>\n",
       "      <td>TP_PRESENCA_LC</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_PRESENCA_MT</th>\n",
       "      <td>TP_PRESENCA_MT</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_LINGUA</th>\n",
       "      <td>TP_LINGUA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_STATUS_REDACAO</th>\n",
       "      <td>TP_STATUS_REDACAO</td>\n",
       "      <td>22.944857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NU_NOTA_REDACAO</th>\n",
       "      <td>NU_NOTA_REDACAO</td>\n",
       "      <td>22.944857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q001</th>\n",
       "      <td>Q001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q002</th>\n",
       "      <td>Q002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q003</th>\n",
       "      <td>Q003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q004</th>\n",
       "      <td>Q004</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q005</th>\n",
       "      <td>Q005</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q006</th>\n",
       "      <td>Q006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q007</th>\n",
       "      <td>Q007</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q008</th>\n",
       "      <td>Q008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q009</th>\n",
       "      <td>Q009</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q010</th>\n",
       "      <td>Q010</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q011</th>\n",
       "      <td>Q011</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q012</th>\n",
       "      <td>Q012</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q013</th>\n",
       "      <td>Q013</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q014</th>\n",
       "      <td>Q014</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q015</th>\n",
       "      <td>Q015</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q016</th>\n",
       "      <td>Q016</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q017</th>\n",
       "      <td>Q017</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q018</th>\n",
       "      <td>Q018</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q019</th>\n",
       "      <td>Q019</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q020</th>\n",
       "      <td>Q020</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q021</th>\n",
       "      <td>Q021</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q022</th>\n",
       "      <td>Q022</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q023</th>\n",
       "      <td>Q023</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q024</th>\n",
       "      <td>Q024</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q025</th>\n",
       "      <td>Q025</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     column_name  percent_missing\n",
       "CO_MUNICIPIO_RESIDENCIA  CO_MUNICIPIO_RESIDENCIA         0.000000\n",
       "NU_IDADE                                NU_IDADE         0.000000\n",
       "TP_SEXO                                  TP_SEXO         0.000000\n",
       "TP_ESTADO_CIVIL                  TP_ESTADO_CIVIL         0.000000\n",
       "TP_COR_RACA                          TP_COR_RACA         0.000000\n",
       "TP_NACIONALIDADE                TP_NACIONALIDADE         0.000000\n",
       "CO_MUNICIPIO_NASCIMENTO  CO_MUNICIPIO_NASCIMENTO         0.000000\n",
       "CO_UF_NASCIMENTO                CO_UF_NASCIMENTO         2.870857\n",
       "SG_UF_NASCIMENTO                SG_UF_NASCIMENTO         2.870857\n",
       "TP_ST_CONCLUSAO                  TP_ST_CONCLUSAO         0.000000\n",
       "TP_ANO_CONCLUIU                  TP_ANO_CONCLUIU         0.000000\n",
       "TP_ESCOLA                              TP_ESCOLA         0.000000\n",
       "TP_ENSINO                              TP_ENSINO        43.498000\n",
       "IN_TREINEIRO                        IN_TREINEIRO         0.000000\n",
       "CO_ESCOLA                              CO_ESCOLA        77.505714\n",
       "CO_MUNICIPIO_ESC                CO_MUNICIPIO_ESC         0.000000\n",
       "SG_UF_ESC                              SG_UF_ESC         2.168000\n",
       "TP_DEPENDENCIA_ADM_ESC    TP_DEPENDENCIA_ADM_ESC        77.505714\n",
       "TP_LOCALIZACAO_ESC            TP_LOCALIZACAO_ESC         0.000000\n",
       "TP_SIT_FUNC_ESC                  TP_SIT_FUNC_ESC         0.000000\n",
       "IN_SURDEZ                              IN_SURDEZ         0.000000\n",
       "IN_DEFICIENCIA_AUDITIVA  IN_DEFICIENCIA_AUDITIVA         0.000000\n",
       "IN_DEFICIENCIA_FISICA      IN_DEFICIENCIA_FISICA         0.000000\n",
       "IN_DEFICIENCIA_MENTAL      IN_DEFICIENCIA_MENTAL         0.000000\n",
       "IN_DEFICIT_ATENCAO            IN_DEFICIT_ATENCAO         0.000000\n",
       "IN_AUTISMO                            IN_AUTISMO         0.000000\n",
       "IN_SEM_RECURSO                    IN_SEM_RECURSO         0.000000\n",
       "IN_LEDOR                                IN_LEDOR         0.000000\n",
       "IN_ACESSO                              IN_ACESSO         0.000000\n",
       "IN_TRANSCRICAO                    IN_TRANSCRICAO         0.000000\n",
       "IN_LIBRAS                              IN_LIBRAS         0.000000\n",
       "IN_TEMPO_ADICIONAL            IN_TEMPO_ADICIONAL         0.000000\n",
       "IN_MAQUINA_BRAILE              IN_MAQUINA_BRAILE         0.000000\n",
       "IN_SALA_ESPECIAL                IN_SALA_ESPECIAL         0.000000\n",
       "CO_MUNICIPIO_PROVA            CO_MUNICIPIO_PROVA         0.000000\n",
       "CO_UF_PROVA                          CO_UF_PROVA         0.000000\n",
       "SG_UF_PROVA                          SG_UF_PROVA         0.000000\n",
       "TP_PRESENCA_CN                    TP_PRESENCA_CN         0.000000\n",
       "TP_PRESENCA_CH                    TP_PRESENCA_CH         0.000000\n",
       "TP_PRESENCA_LC                    TP_PRESENCA_LC         0.000000\n",
       "TP_PRESENCA_MT                    TP_PRESENCA_MT         0.000000\n",
       "TP_LINGUA                              TP_LINGUA         0.000000\n",
       "TP_STATUS_REDACAO              TP_STATUS_REDACAO        22.944857\n",
       "NU_NOTA_REDACAO                  NU_NOTA_REDACAO        22.944857\n",
       "Q001                                        Q001         0.000000\n",
       "Q002                                        Q002         0.000000\n",
       "Q003                                        Q003         0.000000\n",
       "Q004                                        Q004         0.000000\n",
       "Q005                                        Q005         0.000000\n",
       "Q006                                        Q006         0.000000\n",
       "Q007                                        Q007         0.000000\n",
       "Q008                                        Q008         0.000000\n",
       "Q009                                        Q009         0.000000\n",
       "Q010                                        Q010         0.000000\n",
       "Q011                                        Q011         0.000000\n",
       "Q012                                        Q012         0.000000\n",
       "Q013                                        Q013         0.000000\n",
       "Q014                                        Q014         0.000000\n",
       "Q015                                        Q015         0.000000\n",
       "Q016                                        Q016         0.000000\n",
       "Q017                                        Q017         0.000000\n",
       "Q018                                        Q018         0.000000\n",
       "Q019                                        Q019         0.000000\n",
       "Q020                                        Q020         0.000000\n",
       "Q021                                        Q021         0.000000\n",
       "Q022                                        Q022         0.000000\n",
       "Q023                                        Q023         0.000000\n",
       "Q024                                        Q024         0.000000\n",
       "Q025                                        Q025         0.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "pd.set_option('display.max_rows', df.shape[0]+1)\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76daaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73360e80",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8bf1018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## --- variáveis para codificar\n",
    "list_toenc = ['Q001','Q002', 'Q003', 'Q004', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011','Q012', 'Q013',\n",
    "            'Q014', 'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021','Q022', 'Q023', 'Q024', 'Q025',\n",
    "            'CO_MUNICIPIO_RESIDENCIA', 'CO_ESCOLA', 'CO_MUNICIPIO_PROVA',\n",
    "            'SG_UF_PROVA', 'SG_UF_NASCIMENTO', 'SG_UF_ESC','TP_LINGUA','TP_SEXO',\n",
    "            'CO_MUNICIPIO_ESC', 'CO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'CO_UF_PROVA']\n",
    "\n",
    "## --- variáveis mais relevantes para redacao\n",
    "#ft_rd = np.array(['TP_STATUS_REDACAO', 'Q006', 'NU_IDADE', 'Q024', 'Q008', 'TP_ESCOLA', 'Q004', 'TP_ST_CONCLUSAO', 'Q002', 'TP_ANO_CONCLUIU', 'TP_DEPENDENCIA_ADM_ESC', 'Q003', 'Q001', 'Q022', 'Q010','TP_LINGUA', 'Q007', 'Q025', 'Q009', 'Q019', 'TP_ESTADO_CIVIL', 'IN_TREINEIRO', 'Q016', 'Q018', 'CO_ESCOLA', 'TP_LOCALIZACAO_ESC', 'TP_ENSINO', 'CO_MUNICIPIO_ESC', 'Q013', 'CO_MUNICIPIO_PROVA', 'CO_MUNICIPIO_RESIDENCIA', 'CO_UF_PROVA', 'Q021', 'SG_UF_ESC', 'Q014','TP_SEXO', 'TP_SIT_FUNC_ESC', 'CO_UF_NASCIMENTO', 'CO_MUNICIPIO_NASCIMENTO', 'TP_COR_RACA', 'Q023', 'SG_UF_NASCIMENTO', 'SG_UF_PROVA', 'Q020', 'Q012', 'IN_TEMPO_ADICIONAL', 'IN_DEFICIT_ATENCAO', 'Q005', 'Q011', 'TP_NACIONALIDADE','Q015', 'Q017'])\n",
    "ft_rd = list_vars\n",
    "\n",
    "\n",
    "ft_clust = ['Q006', 'NU_IDADE', 'Q024', 'TP_ESCOLA', 'Q004', 'Q002', 'Q003']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa6d2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- encoder\n",
    "is_to_enc = 0\n",
    "if is_to_enc == 1:\n",
    "    ##encoding\n",
    "    enc1 = reduce_mem_usage( pd.read_csv('../input/train.csv', engine='c',\n",
    "                                       usecols=list_toenc) )\n",
    "    enc2 = reduce_mem_usage( pd.read_csv('../input/test.csv', engine='c',\n",
    "                                       usecols=list_toenc) )\n",
    "\n",
    "    enc = pd.concat([enc1,enc2])\n",
    "    del enc1, enc2\n",
    "    encoders = []\n",
    "    for coluna in list_toenc:\n",
    "        if enc[coluna].isna().any() == True:\n",
    "            encoders.append( LabelEncoder().fit( list(set(enc[coluna].astype(str).fillna(\"missing\").replace(\"nan\", \"missing\").unique().tolist())) ) )\n",
    "        else:\n",
    "            encoders.append( LabelEncoder().fit( list(set(enc[coluna].astype(str).unique().tolist())) ) )\n",
    "    del enc\n",
    "    ## saving encoders\n",
    "    for enc, n in zip( encoders, np.arange(len(encoders)) ):\n",
    "        np.save('./Encoders/redacao/classes_%s.npy' % n, enc.classes_)\n",
    "else:\n",
    "    encoders = []\n",
    "    for n in np.arange(len(list_toenc)):\n",
    "        enc = LabelEncoder()\n",
    "        enc.classes_ = np.load('./Encoders/redacao/classes_%s.npy' % n)\n",
    "        encoders.append(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64792f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- substitui notas missing por zero\n",
    "for coluna in notas:\n",
    "    df[coluna] = df[coluna].fillna(0)\n",
    "    \n",
    "## --- substitui valores NaN (variáveis numéricas)  por inteiro arbitrário \n",
    "\n",
    "for coluna in df[list_vars].loc[:2,~df[list_vars].columns.isin(list_toenc)].columns:\n",
    "    df[coluna] = df[coluna].fillna(-32768).astype('int16')\n",
    "    \n",
    "i=0\n",
    "for coluna in list_toenc:\n",
    "    df[coluna] = df[coluna].astype(str).fillna(\"missing\").replace(\"nan\", \"missing\").astype('category')\n",
    "    df[coluna] = encoders[i].transform(df[coluna])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e314cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- redução de cardinalidade\n",
    "df['Q004'] = df['Q004'].apply(lambda x: 0 if x==0 else\n",
    "                                        1 if (x==1) | (x==2) | (x==5) else x-1)\n",
    "df['Q024'] = df['Q024'].apply(lambda x: x if x<3 else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95280af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ccbccb9",
   "metadata": {},
   "source": [
    "### Treino do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5fcb528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- instanciamento do agrupador\n",
    "nclust = 3\n",
    "model = KMeans(n_clusters=nclust)\n",
    "model.fit(df[ft_clust])\n",
    "\n",
    "# atribui cada amostra a um grupo\n",
    "df['CLUSTER'] = model.predict(df[ft_clust])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1fddd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- regressor lbmg\n",
    "regressor_red = make_pipeline(StandardScaler(), lgbm.LGBMRegressor(boosting_type='gbdt', \n",
    "                                                                   learning_rate=0.07, \n",
    "                                                                   max_depth=-1, \n",
    "                                                                   n_estimators=350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db348b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114.02519456806563"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "\n",
    "xval_err = 0\n",
    "y = df['NU_NOTA_REDACAO']\n",
    "for train_index, test_index in kf.split(df[np.append(ft_rd,'CLUSTER')]):\n",
    "    X_train, X_test = df[np.append(ft_rd,'CLUSTER')].iloc[train_index,:], df[np.append(ft_rd,'CLUSTER')].iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    regressor_red.fit(X_train, y_train)\n",
    "    y_pred = pd.Series(regressor_red.predict(X_test))\n",
    "    #y_pred.iloc[X_test[X_test['TP_PRESENCA_CH']!=1].reset_index(drop=True).index] = 0\n",
    "    xval_err += np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "rmse_5cv = xval_err/5\n",
    "rmse_5cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20726efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## --- fit do modelo e gravação dos parâmetros em arquivo\\nregressor_red.fit(df[np.append(ft_rd,'CLUSTER')],\\n                  df['NU_NOTA_REDACAO'].astype('int16'))\\n\\npickle.dump(model, open('./models/redacao.sav', 'wb'))\\n\\n#del df\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"## --- fit do modelo e gravação dos parâmetros em arquivo\n",
    "regressor_red.fit(df[np.append(ft_rd,'CLUSTER')],\n",
    "                  df['NU_NOTA_REDACAO'].astype('int16'))\n",
    "\n",
    "pickle.dump(model, open('./models/redacao.sav', 'wb'))\n",
    "\n",
    "#del df\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2bc9e2",
   "metadata": {},
   "source": [
    "#### Avaliação de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c82e18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113.53623400923703"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[np.append(ft_rd,'CLUSTER')],\n",
    "                                                    df['NU_NOTA_REDACAO'].astype('int16'),\n",
    "                                                    random_state = 42)\n",
    "\n",
    "\n",
    "regressor_red.fit(X_train, y_train)\n",
    "y_pred = pd.Series(regressor_red.predict(X_test))\n",
    "#y_pred.loc[X_test[X_test['TP_STATUS_REDACAO']!=1].reset_index(drop=True).index] = 0\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7612706a",
   "metadata": {},
   "source": [
    "## Predição das Notas de Redação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c652e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pd.read_csv('./submissions.csv', engine='c')\n",
    "df_rd = reduce_mem_usage( pd.read_csv('../input/test.csv', engine='c', usecols=list_vars) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- substitui valores NaN (variáveis numéricas)  por inteiro arbitrário \n",
    "for coluna in df_rd.loc[:2,~df_rd.columns.isin(list_toenc)].columns:\n",
    "    df_rd[coluna] = df_rd[coluna].fillna(-32768).astype('int16')\n",
    "    \n",
    "i=0\n",
    "for coluna in list_toenc:\n",
    "    df_rd[coluna] = df_rd[coluna].astype(str).fillna(\"missing\").replace(\"nan\", \"missing\").astype('category')\n",
    "    df_rd[coluna] = encoders[i].transform(df_rd[coluna])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d77be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- redução de cardinalidade\n",
    "\n",
    "df_rd['Q006'] = df_rd['Q006'].apply(lambda x: 1 if x<=8 else 9)\n",
    "df_rd['Q024'] = df_rd['Q024'].apply(lambda x: x if x<3 else 3)\n",
    "df_rd['Q004'] = df_rd['Q004'].apply(lambda x: 0 if x==0 else\n",
    "                                        1 if (x==1) | (x==2) | (x==5) else x-1)\n",
    "df_rd['Q002'] = df_rd['Q002'].apply(lambda x: 1 if (x==1) | (x==7) else x)\n",
    "\n",
    "df_rd['Q003'] = df_rd['Q003'].apply(lambda x: 0 if x==0 else\n",
    "                                        1 if (x==1) | (x==2) | (x==5) else x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08352208",
   "metadata": {},
   "outputs": [],
   "source": [
    "## clusterização\n",
    "df_rd['CLUSTER'] = model.predict(df_rd[ft_clust])\n",
    "## predição\n",
    "submissions['NU_NOTA_REDACAO'] = regressor_red.predict(df_rd[np.append(ft_rd,'CLUSTER')])\n",
    "submissions['NU_NOTA_REDACAO'].iloc[df_rd[df_rd['TP_STATUS_REDACAO']!=1].index] = 0\n",
    "submissions.to_csv('./submissions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
